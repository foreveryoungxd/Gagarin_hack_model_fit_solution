{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6c0596f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from transformers import TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from datasets import Dataset\n",
    "from random import shuffle\n",
    "from transformers import AutoTokenizer\n",
    "import evaluate\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk import word_tokenize, download\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from natasha import (\n",
    "    Segmenter,\n",
    "    NewsNERTagger,\n",
    "    ORG,\n",
    "    Doc,\n",
    "    NewsEmbedding,\n",
    ")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import catboost\n",
    "import optuna\n",
    "\n",
    "import pickle\n",
    "import string\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "413ce02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = NewsEmbedding()\n",
    "segmenter = Segmenter()\n",
    "ner_tagger = NewsNERTagger(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12480ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"russian\")\n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "russian_stopwords.extend(\n",
    "    ['это', 'как', 'так', 'и', 'в', 'над', 'к', 'до', 'не', 'на', 'но', 'за', 'то', 'с', 'ли', 'а', 'во', 'от', 'со',\n",
    "     'для', 'о', 'же', 'ну', 'вы', 'бы', 'что', 'кто', 'он', 'она', 'оно', 'из-за', 'также'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4bac94",
   "metadata": {},
   "source": [
    "# Чтение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c56c683b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mentions = pd.read_csv('mentions.csv', index_col=0)\n",
    "sentiment = pd.read_csv('sentiment.csv', index_col=0)\n",
    "\n",
    "issuers = pd.read_excel('issuers.xlsx', index_col=0)\n",
    "additional_ner_data = pd.read_excel('names and synonyms.xlsx', index_col=0)\n",
    "\n",
    "# pickle\n",
    "\n",
    "with open('sentiment_texts.pickle', 'rb') as f:\n",
    "    sentiment_texts = pickle.loads(f.read())\n",
    "    \n",
    "with open('mentions texts.pickle', 'rb') as f:\n",
    "    mentions_texts = pickle.loads(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ada4515",
   "metadata": {},
   "source": [
    "Краткое описание дата сета:\n",
    "\n",
    "1)      Корректное нахождение компаний. Релевантные таблицы:\n",
    "a.       **mentions.csv**  - содержит id канала, id сообщения и id упоминаемой компании  \n",
    "b.       **mentions_texts.pickle** – содержит id канала, id сообщения и текст этого сообщения\n",
    "\n",
    "2)      Корректное распознавание сентимента. Релевантные таблицы:\n",
    "a.       **sentiment.csv** – содержит id канала, id сообщения, id компании и score сентимента  \n",
    "b.       **sentiment_texts.pickle** - содержит id канала, id сообщения и текст этого сообщения\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f90183",
   "metadata": {},
   "source": [
    "# Нахождение упоминаний\n",
    "Для начала поработаем с доп. данными по всем возможным вариациям названий компаний"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e643f7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 255 entries, 1 to 274\n",
      "Data columns (total 14 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   EMITENT_FULL_NAME  255 non-null    object \n",
      " 1   VeryOddCompany     0 non-null      float64\n",
      " 2   BGTicker           103 non-null    object \n",
      " 3   BGTicker.1         166 non-null    object \n",
      " 4   Unnamed: 5         207 non-null    object \n",
      " 5   Unnamed: 6         165 non-null    object \n",
      " 6   Unnamed: 7         103 non-null    object \n",
      " 7   Unnamed: 8         53 non-null     object \n",
      " 8   Unnamed: 9         16 non-null     object \n",
      " 9   Unnamed: 10        5 non-null      object \n",
      " 10  Unnamed: 11        2 non-null      object \n",
      " 11  Unnamed: 12        1 non-null      object \n",
      " 12  Unnamed: 13        1 non-null      object \n",
      " 13  Unnamed: 14        1 non-null      object \n",
      "dtypes: float64(1), object(13)\n",
      "memory usage: 29.9+ KB\n"
     ]
    }
   ],
   "source": [
    "additional_ner_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15b207f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_values(row):\n",
    "    return [value for value in row if not pd.isna(value)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4f26433",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_substrings(text:str, substring:str):\n",
    "    if isinstance(text, str):\n",
    "        if substring in text:\n",
    "            text = text.replace(substring, '')\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec0a9f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_ner_data.BGTicker = additional_ner_data.BGTicker.apply(lambda x: delete_substrings(x, 'RX')) #Избавляемся от приставки RX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72dcdb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_ner_data['all_companies_names_mentions'] = additional_ner_data.apply(combine_values, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7815d0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_names_dict = additional_ner_data['all_companies_names_mentions'].to_dict() #Создадим словарь, где id компании сопоставим список из ее встречаемых названий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f769771",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_names_dict = {company_id: list(map(str.lower, company_names)) for company_id, company_names in all_names_dict.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a10b82b",
   "metadata": {},
   "source": [
    "Теперь у нас есть словарь, и по ключу (issuerid) мы получим все вариации упоминания определенной компании  \n",
    "Вернемся к датасетам **mentions** и **mentions_texts** и займемся их предобработкой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2815a54d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ChannelID</th>\n",
       "      <th>messageid</th>\n",
       "      <th>issuerid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.191500e+04</td>\n",
       "      <td>21915.000000</td>\n",
       "      <td>21915.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.201366e+09</td>\n",
       "      <td>48830.289710</td>\n",
       "      <td>125.302441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.079644e+08</td>\n",
       "      <td>77917.270287</td>\n",
       "      <td>78.205528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.138795e+09</td>\n",
       "      <td>4837.000000</td>\n",
       "      <td>53.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.203561e+09</td>\n",
       "      <td>12390.000000</td>\n",
       "      <td>115.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.219485e+09</td>\n",
       "      <td>48683.500000</td>\n",
       "      <td>197.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.868097e+09</td>\n",
       "      <td>278484.000000</td>\n",
       "      <td>274.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ChannelID      messageid      issuerid\n",
       "count  2.191500e+04   21915.000000  21915.000000\n",
       "mean   1.201366e+09   48830.289710    125.302441\n",
       "std    1.079644e+08   77917.270287     78.205528\n",
       "min    0.000000e+00       0.000000     -3.000000\n",
       "25%    1.138795e+09    4837.000000     53.000000\n",
       "50%    1.203561e+09   12390.000000    115.000000\n",
       "75%    1.219485e+09   48683.500000    197.000000\n",
       "max    1.868097e+09  278484.000000    274.000000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mentions.describe() #Наблюдаем выброс в виде issuerid == -3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67e064d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ChannelID</th>\n",
       "      <th>messageid</th>\n",
       "      <th>issuerid</th>\n",
       "      <th>MessageID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.935500e+04</td>\n",
       "      <td>19355.000000</td>\n",
       "      <td>19355.000000</td>\n",
       "      <td>19355.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.200943e+09</td>\n",
       "      <td>52060.347507</td>\n",
       "      <td>124.081839</td>\n",
       "      <td>52060.347507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.781432e+07</td>\n",
       "      <td>81240.604989</td>\n",
       "      <td>78.133251</td>\n",
       "      <td>81240.604989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.001030e+09</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.168461e+09</td>\n",
       "      <td>4943.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>4943.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.203561e+09</td>\n",
       "      <td>13114.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>13114.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.203561e+09</td>\n",
       "      <td>52838.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>52838.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.565800e+09</td>\n",
       "      <td>278484.000000</td>\n",
       "      <td>274.000000</td>\n",
       "      <td>278484.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ChannelID      messageid      issuerid      MessageID\n",
       "count  1.935500e+04   19355.000000  19355.000000   19355.000000\n",
       "mean   1.200943e+09   52060.347507    124.081839   52060.347507\n",
       "std    9.781432e+07   81240.604989     78.133251   81240.604989\n",
       "min    1.001030e+09       5.000000     -2.000000       5.000000\n",
       "25%    1.168461e+09    4943.000000     53.000000    4943.000000\n",
       "50%    1.203561e+09   13114.000000    115.000000   13114.000000\n",
       "75%    1.203561e+09   52838.000000    190.000000   52838.000000\n",
       "max    1.565800e+09  278484.000000    274.000000  278484.000000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mentions_texts.describe() #Наблюдаем выброс в виде issuerid == -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f3cc1fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ChannelID</th>\n",
       "      <th>messageid</th>\n",
       "      <th>issuerid</th>\n",
       "      <th>MessageID</th>\n",
       "      <th>DateAdded</th>\n",
       "      <th>DatePosted</th>\n",
       "      <th>MessageText</th>\n",
       "      <th>IsForward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15771</th>\n",
       "      <td>1203560567</td>\n",
       "      <td>2275</td>\n",
       "      <td>-2</td>\n",
       "      <td>2275</td>\n",
       "      <td>2021-02-06 01:47:00</td>\n",
       "      <td>2017-12-20 07:20:09</td>\n",
       "      <td>PSBR S&amp;P Global Ratings оценило в 93 млрд руб....</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ChannelID  messageid  issuerid  MessageID           DateAdded  \\\n",
       "15771  1203560567       2275        -2       2275 2021-02-06 01:47:00   \n",
       "\n",
       "               DatePosted                                        MessageText  \\\n",
       "15771 2017-12-20 07:20:09  PSBR S&P Global Ratings оценило в 93 млрд руб....   \n",
       "\n",
       "       IsForward  \n",
       "15771      False  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mentions_texts[mentions_texts.issuerid <= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c8ecf40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ChannelID</th>\n",
       "      <th>messageid</th>\n",
       "      <th>issuerid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11217</th>\n",
       "      <td>1280537383</td>\n",
       "      <td>18186</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16881</th>\n",
       "      <td>1203560567</td>\n",
       "      <td>2275</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ChannelID  messageid  issuerid\n",
       "11217  1280537383      18186        -3\n",
       "16881  1203560567       2275        -2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mentions[mentions.issuerid <= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7bb0bb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "mentions_texts = mentions_texts[mentions_texts.issuerid > 0] #Удаление записей с выбросами\n",
    "mentions = mentions[mentions.issuerid > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cb426e",
   "metadata": {},
   "source": [
    "Количество записей в датасетах не совпадает, значит, для некоторых **messageid** имеем несколько **issuerid**, т.е. упоминание  \n",
    "нескольких компаний в одном сообщении"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "256e1efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mentions_texts = mentions_texts[['messageid', 'issuerid', 'MessageText']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "749aabae",
   "metadata": {},
   "outputs": [],
   "source": [
    "mentions = mentions[['messageid', 'issuerid']].groupby('messageid', as_index=False).agg({'issuerid': list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b0ffcbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mentions_texts = mentions_texts.drop_duplicates(subset=['MessageText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c6f16067",
   "metadata": {},
   "outputs": [],
   "source": [
    "mentions_full_data = pd.merge(mentions, mentions_texts[['messageid', 'MessageText']],\n",
    "                              on='messageid',\n",
    "                              how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "706408e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_eng_words = [] #Сделаем словарь, в котором будут лежать названия компаний на латинице и которые надо оставить при форматировании текстов\n",
    "for values in all_names_dict.values():\n",
    "    for item in values:\n",
    "        english_words = re.findall(r'\\b[a-zA-Z]{5,}\\b', item)\n",
    "        dict_eng_words.extend(english_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "da06a15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "latin_comps_mentions = [] #Начнем удалять из корпуса текстов MessageText названия компаний на английском языке, которые точно не являются искомыми\n",
    "\n",
    "for text in mentions_full_data.MessageText:\n",
    "    latin_words = re.findall(r'\\b[a-zA-Z]{5,}\\b', text) #находим все компании на английском/транслите, длиной > 4 символов\n",
    "    \n",
    "    latin_comps_mentions.extend(latin_words)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fe847772",
   "metadata": {},
   "outputs": [],
   "source": [
    "for latin_word in latin_comps_mentions:\n",
    "    if latin_word.lower() in dict_eng_words:\n",
    "        latin_comps_mentions.remove(latin_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fa66f9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "latin_comps_mentions = list(set(latin_comps_mentions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2879a697",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_tokens = [\n",
    "    'млрд', \n",
    "    'млн', \n",
    "    'трлн',\n",
    "    'руб',\n",
    "    'года',\n",
    "    'компании', \n",
    "    'компания', \n",
    "    'компаний', \n",
    "    'акции', \n",
    "    'акций',\n",
    "    'рублей',\n",
    "    'год',\n",
    "    'на',\n",
    "    'году',\n",
    "    'по',\n",
    "    'сша',\n",
    "    'результаты',\n",
    "    'мсфо',\n",
    "    'нефть', \n",
    "    'нефти',\n",
    "    'ru',\n",
    "    'директоров', \n",
    "    'Директоров'\n",
    "    'при',\n",
    "    'система',\n",
    "    '30мск', \n",
    "    '00мск',\n",
    "    'совет', \n",
    "    'акционеров', ''\n",
    "    'ak47pfl',\n",
    "    'если',\n",
    "    'вопроc',\n",
    "    'новости',\n",
    "    'подробнее',\n",
    "    'российских',\n",
    "    'рамках',\n",
    "    'ipo',\n",
    "    'взгляд',\n",
    "    'рф',\n",
    "    'россии', \n",
    "    'россия', \n",
    "    'россие',\n",
    "    'не',\n",
    "    'дня',\n",
    "    'дивиденды',\n",
    "    'отчетность', \n",
    "    'отчётность',\n",
    "    'биржа',\n",
    "    'бирже',\n",
    "    'биржи',\n",
    "    'кв',\n",
    "    'мск',\n",
    "    'гг',\n",
    "    'фн',\n",
    "    'upd'    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "845816c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_company_name_natasha = [\n",
    "    'лонг', \n",
    "    'мира', \n",
    "    'горячую', \n",
    "    'казначейство', \n",
    "    'распадской', \n",
    "    'детского', \n",
    "    'ведомости', \n",
    "    'акционеры', \n",
    "    'шорт', \n",
    "    'десятку', \n",
    "    'акция'\n",
    "    'цб',\n",
    "    'мосбиржи', \n",
    "    'мосбиржа',\n",
    "    'банка',\n",
    "    'сд',\n",
    "    'компания',\n",
    "    'совет',\n",
    "    'система',\n",
    "    'прайм',\n",
    "    'ао',\n",
    "    'рао',\n",
    "    'московской',\n",
    "    'тасс',\n",
    "    'фрс',\n",
    "    'минфин',\n",
    "    'группы',\n",
    "    'биржа',\n",
    "    'бирже',\n",
    "    'биржи',\n",
    "    'en',\n",
    "    'фас',\n",
    "    'интерфакс',\n",
    "    'за',\n",
    "    'выручка',\n",
    "    'не',\n",
    "    'менеджмент',\n",
    "    'инвестиции', \n",
    "    'инвестиций',\n",
    "    'сми',\n",
    "    'флэт',\n",
    "    'фонд',\n",
    "    'топ',\n",
    "    'новости',\n",
    "    'боковик',\n",
    "    'минфина',\n",
    "    'системы',\n",
    "    'центр',\n",
    "    'фн',\n",
    "    'сегодня',\n",
    "    'рекомендовал',\n",
    "    'прогноз',\n",
    "    'сигналов',\n",
    "    'от',\n",
    "    'размере',\n",
    "    'риа',\n",
    "    'объем',\n",
    "    'аутсайдеры',\n",
    "    'отчет',\n",
    "    'правления',\n",
    "    'московский',\n",
    "    'служба',\n",
    "    'технический',\n",
    "    'приказ',\n",
    "    'интерфакса',\n",
    "    'распадской',\n",
    "    'арбитражный',\n",
    "    'до'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e56f1a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def message_text_preprocess(text): #Функция для предобработки текста\n",
    "    remove_punctuation = '!\"#$%&\\'*+,./:;<=>?@[\\\\]^_`{|}~``🇷🇺'')('\n",
    "    text = re.sub(r'\\s+', ' ', text) #Заменяем последовательности пробелов и других пробельных символов на один пробел\n",
    "    text = re.sub(r'(?<=[^\\w\\d])-|-(?=[^\\w\\d])|[^\\w\\d\\s-]', '', text) #Удаляем все символы, кроме букв, цифр, пробелов и дефисов\n",
    "    text = re.sub(r'\\+\\d{1,2}\\s\\(\\d{3}\\)\\s\\d{3}-\\d{2}-\\d{2}', '', text) #удаляем телефонные номера\n",
    "    text = re.sub(r'https?://\\S+', '', text) #удаляем ссылки\n",
    "    text = re.sub(r'\\s+', ' ', text) #еще раз удаляем пробелы, если таковые остались\n",
    "    text = re.sub('•', '', text)\n",
    "    text = re.sub(\"''\", '', text)\n",
    "    text = re.sub(r'[«»]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text) #удаляем все цифры\n",
    "    text = re.sub(r'\\b\\w\\b', '', text) #удаляем одиночные символы\n",
    "\n",
    "    \n",
    "    tokens = word_tokenize(text) #Токенизируем текст\n",
    "    filtered_tokens = [token for token in tokens if token not in remove_punctuation and token not in russian_stopwords and token.lower() not in latin_comps_mentions and token.lower() not in most_common_tokens]\n",
    "    \n",
    "    return \" \".join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a89d18e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 49s\n",
      "Wall time: 1min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mentions_full_data['MessageText'] = mentions_full_data['MessageText'].apply(message_text_preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba7bf21-8655-40f6-9592-64eb7c1c3234",
   "metadata": {},
   "source": [
    "Блок для выявления самых часто встречаемых слов, от которых можно избавиться. Добавляются в список most_common_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "174e3a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "mes_text_corpus = []\n",
    "for value_list in mentions_full_data.MessageText:\n",
    "    tokens = word_tokenize(value_list)\n",
    "    mes_text_corpus.extend(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "75a6b24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(mes_text_corpus)\n",
    "vocabulary = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b666f5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_counts = X.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f6eb24bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_freq = {token: count for token, count in zip(vocabulary, token_counts.tolist()[0])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "68f7160e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_tokens = sorted(token_freq.items(), key=lambda x: x[1], reverse=True)\n",
    "top_tokens = sorted_tokens[:200]  # Первые 10 самых частых токенов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8947d2c8",
   "metadata": {},
   "source": [
    "# Идея:  \n",
    "• с помощью библиотеки natasha извлекаем названия компаний из корпуса текстов (ограничения для ускорения алгоритма: извлекаем максимум 3 именованные сущности, от каждой оставляем первые 10 симоволов  \n",
    "• на словаре из всех названий компаний и общего корпуса, извлеченного natasha'ей обучаем tf-idf  \n",
    "• после этого для предсказания id упоминаемоей компании берем то, что извлекла natasha, векторизуем и сравниваем с векторами из словаря методом косинусного сходства. id компании с топ-1 скором извлекаем сразу, а если разница между топ-1 и топ-2 не более 0.05, то извлекаем id обеих компаний"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "611cea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_natasha_mentions(text):\n",
    "    doc = Doc(text)\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_ner(ner_tagger) \n",
    "    orgs = []\n",
    "    for item in doc.spans:\n",
    "        if len(orgs) >= 3: #Если уже найдено 3 организации, прекращаем извлечение\n",
    "            break\n",
    "        if item.type == 'ORG' and item.text.lower() not in not_company_name_natasha:\n",
    "            orgs.append(item.text[:10])\n",
    "    return orgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "39e9d0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 5min 2s\n",
      "Wall time: 1min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mentions_full_data['natasha_mentions'] = mentions_full_data['MessageText'].apply(fill_natasha_mentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7b58945c-453c-4d2f-afc4-2bea61acf027",
   "metadata": {},
   "outputs": [],
   "source": [
    "mes_natasha_corpus = [] #ищем топ самых встречаемых слов по результатам работы natasha, которые точно не являются компанией, кладем в not_company_name_natasha\n",
    "for value_list in mentions_full_data.natasha_mentions:\n",
    "    text = ' '.join(value_list)  #Объединяем значения в одну строку\n",
    "    tokens = word_tokenize(text)  #Токенизируем строку\n",
    "    mes_natasha_corpus.extend(tokens) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "43fe9ed5-1b7f-4502-bb0e-b4ce0acb740d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(mes_natasha_corpus)\n",
    "vocabulary = vectorizer.get_feature_names_out()\n",
    "\n",
    "token_counts = X.sum(axis=0)\n",
    "token_freq = {token: count for token, count in zip(vocabulary, token_counts.tolist()[0])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "171187b0-f59c-4f3a-9ae4-7e996599b2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_tokens = sorted(token_freq.items(), key=lambda x: x[1], reverse=True)\n",
    "top_tokens = sorted_tokens[:400]  # Первые топ __ самых частых токенов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bef11fe-46d6-4fea-a62f-719d994d0ad2",
   "metadata": {},
   "source": [
    "# -------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a38e25b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tokens = []\n",
    "for value_list in all_names_dict.values(): #Проходим по всем значениям в словаре all_names_dict\n",
    "    text = ' '.join(value_list) #Объединяем значения в одну строку\n",
    "    tokens = word_tokenize(text) #Токенизируем строку\n",
    "    corpus_tokens.extend(tokens) #Добавляем токены в список корпуса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9705726d",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_punctuation = '!\"#$%&\\'*+,./:;<=>?@[\\\\]''^_`{|}~``🇷🇺'')('"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ae52d5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tokens = [word for word in corpus_tokens if word.lower() not in remove_punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2a6ab0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tokens = [token.replace(\"'\", \"\").replace('\"', '') for token in corpus_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a8035d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tokens_natasha = []\n",
    "for mention_list in mentions_full_data['natasha_mentions']:\n",
    "    text = ' '.join(mention_list) #Объединяем значения в одну строку\n",
    "    tokens = word_tokenize(text) #Токенизируем строку\n",
    "    corpus_tokens_natasha.extend(tokens) #Добавляем токены в список корпуса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f08576b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#corpus_tokens_natasha = [word for word in corpus_tokens_natasha if word.lower() not in remove_punctuation]\n",
    "corpus_tokens_natasha = [token.replace(\"'\", \"\").replace('\"', '') for token in corpus_tokens_natasha]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "751f5687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(max_features=1087)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_features=1087)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(max_features=1087)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tfidf = TfidfVectorizer(max_features=1087) \n",
    "model_tfidf.fit_transform(corpus_tokens)\n",
    "model_tfidf.fit(corpus_tokens_natasha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f356ae1f-0482-40f8-9e51-772d43d13609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_companies(model_tfidf, mentions, all_names_dict): #функция для алгоритмического предсказания упоминания компании в тексте\n",
    "    if len(mentions) == 0: #для случая отсутствия выявленных сущностей в тексте\n",
    "        return 0\n",
    "    natasha_vector = model_tfidf.transform([' '.join(mentions)]) #Преобразуем упоминания Natasha и компаний в вектора TF-IDF\n",
    "    company_vectors = model_tfidf.transform([' '.join(company_names) for company_names in all_names_dict.values()])\n",
    "    \n",
    "    similarities = cosine_similarity(natasha_vector, company_vectors) #Находим косинусное расстояние между упоминаниями и компаниями\n",
    "\n",
    "    best_company_id = similarities.argsort(axis=1)[:, -1] + 1  #компания с наивысшим скором\n",
    "    second_best_company_id = similarities.argsort(axis=1)[:, -2] + 1  #компания со вторым по величине скором\n",
    "\n",
    "    if similarities.max(axis=1)[0] - np.partition(similarities, -2, axis=1)[:, -2][0] > 0.05: #условие разницы топ-1 и топ-2 скора\n",
    "        return best_company_id\n",
    "    else:\n",
    "        return [best_company_id[0], second_best_company_id[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2d999923-4164-4a1b-89cd-ff9d1f46aeb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 11s\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mentions_full_data['predict'] = mentions_full_data['natasha_mentions'].apply(lambda x: find_best_companies(model_tfidf, x, all_names_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "03ff8db3-3941-411f-aac6-dbecdc352fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_best_companies(model_tfidf, mentions_full_data.natasha_mentions[0], all_names_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94558440-3738-4924-9346-51222ab80207",
   "metadata": {},
   "source": [
    "# Определение тональности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0717bc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_texts = sentiment_texts[['issuerid', 'SentimentScore', 'MessageText']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a6d9e278-3fcc-4153-b5bd-ecd40e11fb59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 5, 3, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_texts.SentimentScore.unique() #удалим наблюдения, где сентимент==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f3e35e3c-9253-4565-a91a-eb958ead32b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_texts = sentiment_texts[sentiment_texts.SentimentScore != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "94631847-dc9e-476f-a194-c4d09ac00780",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_texts = sentiment_texts.groupby('MessageText', as_index=False).agg({'issuerid': list, 'SentimentScore': list}) #Группируем по одинаковым текстам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b7669766-3a28-4efb-b24d-0154ddc7c98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 45.5 s\n",
      "Wall time: 45.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentiment_texts.MessageText = sentiment_texts.MessageText.apply(message_text_preprocess) #Предобрабатываем текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a646e25a-aab4-405f-853c-79641f5942f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 47s\n",
      "Wall time: 27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentiment_texts['natasha_mentions'] = sentiment_texts['MessageText'].apply(fill_natasha_mentions) #Выявляем именованные сущности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "48b68af9-ddae-4302-8d24-288a5f9e12c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_texts['predict_id'] = sentiment_texts['natasha_mentions'].apply(lambda x: find_best_companies(model_tfidf, x, all_names_dict)) #Предсказываем id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "bfd958ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MessageText</th>\n",
       "      <th>issuerid</th>\n",
       "      <th>SentimentScore</th>\n",
       "      <th>natasha_mentions</th>\n",
       "      <th>predict_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>235</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>вводят санкции против банков Московский кредит...</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>[Московский, ВПК, ТАСС TCSG ]</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>вводят санкции против банков Московский кредит...</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>[Московский, ВПК, ТАСС TCSG ]</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>АКРОН БУДЕТ ОСПАРИВАТЬ РЕШЕНИЕ ПОЛЬШИ АКЦИЯМ A...</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>[АКРОН БУДЕ, МЕЖДУНАРОД, НЕЗАКОННЫМ]</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>АЛРОСА выплатить итогам первого полугодия ситу...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[АЛРОСА]</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7033</th>\n",
       "      <td>компанию Мечел эффект отмены экспортных пошлин...</td>\n",
       "      <td>99</td>\n",
       "      <td>4</td>\n",
       "      <td>[Мечел, Мечела, Мечел]</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7034</th>\n",
       "      <td>компанию Мечел - долгожданный разворот Дмитрий...</td>\n",
       "      <td>99</td>\n",
       "      <td>5</td>\n",
       "      <td>[Мечел, Мечел, Мечел]</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7035</th>\n",
       "      <td>Мечел потенциалом роста свыше конца итогам дек...</td>\n",
       "      <td>99</td>\n",
       "      <td>4</td>\n",
       "      <td>[Мечел, Мечел, Мечела]</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7036</th>\n",
       "      <td>Мечел анализ ключевых БКС Мы по-прежнему счита...</td>\n",
       "      <td>99</td>\n",
       "      <td>4</td>\n",
       "      <td>[Мечел, БКС, Мечел]</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7037</th>\n",
       "      <td>АФК обещает дивы Верим Основатель AFKS Владими...</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>[АФК, AFKS, АФК Финанс]</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28774 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            MessageText issuerid  \\\n",
       "0                                                            235   \n",
       "1     вводят санкции против банков Московский кредит...      100   \n",
       "1     вводят санкции против банков Московский кредит...      100   \n",
       "2     АКРОН БУДЕТ ОСПАРИВАТЬ РЕШЕНИЕ ПОЛЬШИ АКЦИЯМ A...       24   \n",
       "3     АЛРОСА выплатить итогам первого полугодия ситу...        4   \n",
       "...                                                 ...      ...   \n",
       "7033  компанию Мечел эффект отмены экспортных пошлин...       99   \n",
       "7034  компанию Мечел - долгожданный разворот Дмитрий...       99   \n",
       "7035  Мечел потенциалом роста свыше конца итогам дек...       99   \n",
       "7036  Мечел анализ ключевых БКС Мы по-прежнему счита...       99   \n",
       "7037  АФК обещает дивы Верим Основатель AFKS Владими...       26   \n",
       "\n",
       "     SentimentScore                      natasha_mentions predict_id  \n",
       "0                 4                                    []          0  \n",
       "1                 2         [Московский, ВПК, ТАСС TCSG ]        207  \n",
       "1                 2         [Московский, ВПК, ТАСС TCSG ]        137  \n",
       "2                 2  [АКРОН БУДЕ, МЕЖДУНАРОД, НЕЗАКОННЫМ]         24  \n",
       "3                 4                              [АЛРОСА]         27  \n",
       "...             ...                                   ...        ...  \n",
       "7033              4                [Мечел, Мечела, Мечел]         99  \n",
       "7034              5                 [Мечел, Мечел, Мечел]         99  \n",
       "7035              4                [Мечел, Мечел, Мечела]         99  \n",
       "7036              4                   [Мечел, БКС, Мечел]         99  \n",
       "7037              4               [АФК, AFKS, АФК Финанс]         26  \n",
       "\n",
       "[28774 rows x 5 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_texts_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "bb2f9658-c749-476e-a2cb-6bbfa0b964c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_texts_ = sentiment_texts.explode('issuerid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "51728835-4ba2-4272-b96b-04362792698e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_texts_ = sentiment_texts_.explode('predict_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "11dd9ba5-b2be-451f-bef2-f65fbdbcd91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_texts_ = sentiment_texts_.explode('SentimentScore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068a8c04-7a6c-4fb0-9a00-bcff8e076aa8",
   "metadata": {},
   "source": [
    "# Бейзлайн - tf-idf + Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "db372e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(sentiment_texts_, test_size=0.2, random_state=42)\n",
    "test, valid = train_test_split(test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "97dfd0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfidf = model_tfidf.fit_transform(train['MessageText'].values)\n",
    "test_tfidf = model_tfidf.transform(test['MessageText'].values)\n",
    "valid_tfidf = model_tfidf.transform(valid['MessageText'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "cbd79250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2min 15s\n",
      "Wall time: 2min 15s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(train_tfidf, train['SentimentScore'].astype(int).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "62fd0c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 125 ms\n",
      "Wall time: 118 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7994438651372958"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "predictions = clf.predict(test_tfidf)\n",
    "accuracy_score(predictions, test['SentimentScore'].astype(int).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f3b0ecbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RF_clf.joblib']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(clf, 'RF_clf.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb20fa6",
   "metadata": {},
   "source": [
    "# Catboost (градиентный бустинг)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "649428eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pool = catboost.Pool(train_tfidf, label=train['SentimentScore'].values)\n",
    "test_pool = catboost.Pool(test_tfidf, label=test['SentimentScore'].values)\n",
    "valid_pool = catboost.Pool(valid_tfidf, label=valid['SentimentScore'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "8152d11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5733959\ttest: 0.5672576\tbest: 0.5672576 (0)\ttotal: 225ms\tremaining: 5m 36s\n",
      "100:\tlearn: 0.7269212\ttest: 0.7278415\tbest: 0.7292318 (95)\ttotal: 7.57s\tremaining: 1m 44s\n",
      "200:\tlearn: 0.7651505\ttest: 0.7518248\tbest: 0.7542579 (195)\ttotal: 14.8s\tremaining: 1m 35s\n",
      "300:\tlearn: 0.7864373\ttest: 0.7643379\tbest: 0.7664234 (255)\ttotal: 22.2s\tremaining: 1m 28s\n",
      "400:\tlearn: 0.7992962\ttest: 0.7737226\tbest: 0.7747654 (391)\ttotal: 29.7s\tremaining: 1m 21s\n",
      "500:\tlearn: 0.8079847\ttest: 0.7803267\tbest: 0.7806743 (495)\ttotal: 37s\tremaining: 1m 13s\n",
      "600:\tlearn: 0.8157609\ttest: 0.7817171\tbest: 0.7834550 (547)\ttotal: 44.3s\tremaining: 1m 6s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.7834549878\n",
      "bestIteration = 547\n",
      "\n",
      "Shrink model to first 548 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1a1c010bc90>"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_catboost = catboost.CatBoostClassifier(random_state=42, iterations=1500, learning_rate=0.0999, \n",
    "                                             depth=5, l2_leaf_reg=0.11, eval_metric='Accuracy', colsample_bylevel=0.1308)\n",
    "model_catboost.fit(train_pool,\n",
    "                  eval_set = test_pool,\n",
    "                  verbose=100,\n",
    "                  early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "c7aa6dcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7748436414176512"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(valid['SentimentScore'].astype(int).values, model_catboost.predict(valid_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188d4a53-08d3-4efa-a74d-4dd2bee4edd1",
   "metadata": {},
   "source": [
    "# Попробуем потюнить гиперпараметры catboost с помощью optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "ac6c3dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_catboost(trial):\n",
    "\n",
    "    params = {\n",
    "         'iterations': trial.suggest_int('iterations', 500, 2000, step=200),\n",
    "         'depth': trial.suggest_int('depth', 3, 6),\n",
    "         'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2 , step=0.01),\n",
    "         'auto_class_weights': 'SqrtBalanced',\n",
    "         'eval_metric': \"Accuracy\",\n",
    "         'loss_function': 'MultiClass',\n",
    "         'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-2, 1,log=True),\n",
    "         'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.1, 1.0),\n",
    "         'random_seed': 42\n",
    "    }\n",
    "\n",
    "\n",
    "    clf_catboost = catboost.CatBoostClassifier(**params)\n",
    "    clf_catboost.fit(train_pool,\n",
    "                      eval_set = test_pool, plot=False, verbose=100,\n",
    "                    early_stopping_rounds=100)\n",
    " \n",
    "    return accuracy_score(valid['SentimentScore'].astype(int).values, clf_catboost.predict(valid_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "108c5c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-14 05:52:15,539] A new study created in memory with name: catboost-seed42\n"
     ]
    }
   ],
   "source": [
    "study_catboost = optuna.create_study(study_name='catboost-seed42',\n",
    "                                direction='maximize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "bc4c2072",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0fa3c1b48ea477d80fa44ee26e878f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alrxp\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [500, 2000] and step=200, but the range is not divisible by `step`. It will be replaced by [500, 1900].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5001306\ttest: 0.4783352\tbest: 0.4783352 (0)\ttotal: 215ms\tremaining: 3m 56s\n",
      "100:\tlearn: 0.5614815\ttest: 0.5495169\tbest: 0.5502590 (98)\ttotal: 24.6s\tremaining: 4m 3s\n",
      "200:\tlearn: 0.5983177\ttest: 0.5872105\tbest: 0.5872105 (200)\ttotal: 49s\tremaining: 3m 39s\n",
      "300:\tlearn: 0.6243811\ttest: 0.6201178\tbest: 0.6206276 (298)\ttotal: 1m 13s\tremaining: 3m 16s\n",
      "400:\tlearn: 0.6499665\ttest: 0.6422530\tbest: 0.6425706 (364)\ttotal: 1m 40s\tremaining: 2m 55s\n",
      "500:\tlearn: 0.6543080\ttest: 0.6439926\tbest: 0.6445653 (491)\ttotal: 2m 8s\tremaining: 2m 33s\n",
      "600:\tlearn: 0.6647748\ttest: 0.6520296\tbest: 0.6523549 (595)\ttotal: 2m 33s\tremaining: 2m 7s\n",
      "700:\tlearn: 0.6724939\ttest: 0.6579511\tbest: 0.6579511 (684)\ttotal: 2m 59s\tremaining: 1m 42s\n",
      "800:\tlearn: 0.6784593\ttest: 0.6644937\tbest: 0.6645717 (760)\ttotal: 3m 24s\tremaining: 1m 16s\n",
      "900:\tlearn: 0.6883145\ttest: 0.6778857\tbest: 0.6781330 (892)\ttotal: 3m 48s\tremaining: 50.5s\n",
      "1000:\tlearn: 0.6951881\ttest: 0.6837259\tbest: 0.6837259 (998)\ttotal: 4m 14s\tremaining: 25.1s\n",
      "1099:\tlearn: 0.6980045\ttest: 0.6884706\tbest: 0.6884706 (1091)\ttotal: 4m 38s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.6884706374\n",
      "bestIteration = 1091\n",
      "\n",
      "Shrink model to first 1092 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alrxp\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [500, 2000] and step=200, but the range is not divisible by `step`. It will be replaced by [500, 1900].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5076179\ttest: 0.4922546\tbest: 0.4922546 (0)\ttotal: 147ms\tremaining: 2m 41s\n",
      "100:\tlearn: 0.7252107\ttest: 0.7028519\tbest: 0.7040753 (96)\ttotal: 23.8s\tremaining: 3m 55s\n",
      "200:\tlearn: 0.7719510\ttest: 0.7296778\tbest: 0.7306538 (199)\ttotal: 45.1s\tremaining: 3m 21s\n",
      "300:\tlearn: 0.7970614\ttest: 0.7391236\tbest: 0.7391236 (296)\ttotal: 1m 6s\tremaining: 2m 56s\n",
      "400:\tlearn: 0.8098321\ttest: 0.7408820\tbest: 0.7470831 (367)\ttotal: 1m 27s\tremaining: 2m 33s\n",
      "500:\tlearn: 0.8215744\ttest: 0.7502373\tbest: 0.7511855 (494)\ttotal: 1m 49s\tremaining: 2m 10s\n",
      "600:\tlearn: 0.8299044\ttest: 0.7525435\tbest: 0.7539787 (560)\ttotal: 2m 10s\tremaining: 1m 48s\n",
      "700:\tlearn: 0.8362632\ttest: 0.7569006\tbest: 0.7578272 (668)\ttotal: 2m 32s\tremaining: 1m 26s\n",
      "800:\tlearn: 0.8402210\ttest: 0.7556851\tbest: 0.7584477 (746)\ttotal: 2m 53s\tremaining: 1m 4s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.7584477436\n",
      "bestIteration = 746\n",
      "\n",
      "Shrink model to first 747 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alrxp\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [500, 2000] and step=200, but the range is not divisible by `step`. It will be replaced by [500, 1900].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.4993854\ttest: 0.4793577\tbest: 0.4793577 (0)\ttotal: 68.5ms\tremaining: 2m 9s\n",
      "100:\tlearn: 0.6419032\ttest: 0.6377060\tbest: 0.6377060 (100)\ttotal: 6.81s\tremaining: 2m 1s\n",
      "200:\tlearn: 0.6821897\ttest: 0.6708889\tbest: 0.6708889 (200)\ttotal: 13.4s\tremaining: 1m 53s\n",
      "300:\tlearn: 0.7034279\ttest: 0.6927091\tbest: 0.6950227 (283)\ttotal: 20.8s\tremaining: 1m 50s\n",
      "400:\tlearn: 0.7233298\ttest: 0.7045264\tbest: 0.7045264 (400)\ttotal: 27.4s\tremaining: 1m 42s\n",
      "500:\tlearn: 0.7370714\ttest: 0.7114952\tbest: 0.7117426 (497)\ttotal: 33.7s\tremaining: 1m 34s\n",
      "600:\tlearn: 0.7484052\ttest: 0.7185641\tbest: 0.7196543 (594)\ttotal: 39.8s\tremaining: 1m 26s\n",
      "700:\tlearn: 0.7591119\ttest: 0.7268940\tbest: 0.7271414 (692)\ttotal: 46s\tremaining: 1m 18s\n",
      "800:\tlearn: 0.7687927\ttest: 0.7292860\tbest: 0.7301911 (794)\ttotal: 52.6s\tremaining: 1m 12s\n",
      "900:\tlearn: 0.7759285\ttest: 0.7316013\tbest: 0.7316793 (860)\ttotal: 59.6s\tremaining: 1m 6s\n",
      "1000:\tlearn: 0.7820000\ttest: 0.7346640\tbest: 0.7346856 (983)\ttotal: 1m 6s\tremaining: 60s\n",
      "1100:\tlearn: 0.7871242\ttest: 0.7358229\tbest: 0.7363177 (1094)\ttotal: 1m 13s\tremaining: 53s\n",
      "1200:\tlearn: 0.7906674\ttest: 0.7346060\tbest: 0.7373222 (1123)\ttotal: 1m 19s\tremaining: 46.2s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.7373222334\n",
      "bestIteration = 1123\n",
      "\n",
      "Shrink model to first 1124 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alrxp\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [500, 2000] and step=200, but the range is not divisible by `step`. It will be replaced by [500, 1900].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.4844840\ttest: 0.4715607\tbest: 0.4715607 (0)\ttotal: 85.4ms\tremaining: 1m 50s\n",
      "100:\tlearn: 0.6824615\ttest: 0.6794323\tbest: 0.6794323 (100)\ttotal: 16.1s\tremaining: 3m 10s\n",
      "200:\tlearn: 0.7298625\ttest: 0.7097011\tbest: 0.7124744 (194)\ttotal: 33.4s\tremaining: 3m 2s\n",
      "300:\tlearn: 0.7569110\ttest: 0.7242154\tbest: 0.7242319 (267)\ttotal: 51.2s\tremaining: 2m 49s\n",
      "400:\tlearn: 0.7756952\ttest: 0.7265394\tbest: 0.7322430 (354)\ttotal: 1m 8s\tremaining: 2m 33s\n",
      "500:\tlearn: 0.7878435\ttest: 0.7354554\tbest: 0.7365728 (428)\ttotal: 1m 26s\tremaining: 2m 17s\n",
      "600:\tlearn: 0.7994708\ttest: 0.7385537\tbest: 0.7438625 (574)\ttotal: 1m 43s\tremaining: 2m\n",
      "700:\tlearn: 0.8091197\ttest: 0.7479283\tbest: 0.7480842 (690)\ttotal: 2m 2s\tremaining: 1m 44s\n",
      "800:\tlearn: 0.8169065\ttest: 0.7479633\tbest: 0.7495970 (785)\ttotal: 2m 20s\tremaining: 1m 27s\n",
      "900:\tlearn: 0.8231049\ttest: 0.7506429\tbest: 0.7513221 (896)\ttotal: 2m 37s\tremaining: 1m 9s\n",
      "1000:\tlearn: 0.8287445\ttest: 0.7513356\tbest: 0.7523116 (972)\ttotal: 2m 54s\tremaining: 52s\n",
      "1100:\tlearn: 0.8338657\ttest: 0.7523822\tbest: 0.7546881 (1042)\ttotal: 3m 12s\tremaining: 34.8s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.7546880922\n",
      "bestIteration = 1042\n",
      "\n",
      "Shrink model to first 1043 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alrxp\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [500, 2000] and step=200, but the range is not divisible by `step`. It will be replaced by [500, 1900].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.4777310\ttest: 0.4629500\tbest: 0.4629500 (0)\ttotal: 59.6ms\tremaining: 1m 41s\n",
      "100:\tlearn: 0.6914280\ttest: 0.6697465\tbest: 0.6726950 (98)\ttotal: 6.24s\tremaining: 1m 38s\n",
      "200:\tlearn: 0.7335890\ttest: 0.7065198\tbest: 0.7078501 (176)\ttotal: 12.1s\tremaining: 1m 30s\n",
      "300:\tlearn: 0.7599923\ttest: 0.7296911\tbest: 0.7296911 (300)\ttotal: 17.8s\tremaining: 1m 22s\n",
      "400:\tlearn: 0.7760616\ttest: 0.7242300\tbest: 0.7306957 (303)\ttotal: 23.8s\tremaining: 1m 17s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.7306956963\n",
      "bestIteration = 303\n",
      "\n",
      "Shrink model to first 304 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alrxp\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [500, 2000] and step=200, but the range is not divisible by `step`. It will be replaced by [500, 1900].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.4703165\ttest: 0.4610996\tbest: 0.4610996 (0)\ttotal: 44.3ms\tremaining: 1m 24s\n",
      "100:\tlearn: 0.5955340\ttest: 0.5871799\tbest: 0.5876816 (96)\ttotal: 4.8s\tremaining: 1m 25s\n",
      "200:\tlearn: 0.6419540\ttest: 0.6437445\tbest: 0.6437445 (199)\ttotal: 10.1s\tremaining: 1m 25s\n",
      "300:\tlearn: 0.6623049\ttest: 0.6517967\tbest: 0.6519246 (296)\ttotal: 15.3s\tremaining: 1m 21s\n",
      "400:\tlearn: 0.6823839\ttest: 0.6735754\tbest: 0.6742330 (399)\ttotal: 20.1s\tremaining: 1m 15s\n",
      "500:\tlearn: 0.6930340\ttest: 0.6856851\tbest: 0.6861582 (492)\ttotal: 24.9s\tremaining: 1m 9s\n",
      "600:\tlearn: 0.7024612\ttest: 0.6931236\tbest: 0.6958597 (586)\ttotal: 29.8s\tremaining: 1m 4s\n",
      "700:\tlearn: 0.7098353\ttest: 0.6993683\tbest: 0.6995721 (695)\ttotal: 34.9s\tremaining: 59.7s\n",
      "800:\tlearn: 0.7158764\ttest: 0.7046891\tbest: 0.7046891 (797)\ttotal: 39.7s\tremaining: 54.4s\n",
      "900:\tlearn: 0.7267800\ttest: 0.7074465\tbest: 0.7079127 (866)\ttotal: 44.5s\tremaining: 49.4s\n",
      "1000:\tlearn: 0.7329412\ttest: 0.7103656\tbest: 0.7111856 (964)\ttotal: 49.2s\tremaining: 44.2s\n",
      "1100:\tlearn: 0.7390775\ttest: 0.7153374\tbest: 0.7155848 (1096)\ttotal: 54.9s\tremaining: 39.8s\n",
      "1200:\tlearn: 0.7435539\ttest: 0.7159521\tbest: 0.7176074 (1188)\ttotal: 1m\tremaining: 35s\n",
      "1300:\tlearn: 0.7494826\ttest: 0.7182029\tbest: 0.7182029 (1282)\ttotal: 1m 4s\tremaining: 29.9s\n",
      "1400:\tlearn: 0.7545448\ttest: 0.7198325\tbest: 0.7211624 (1378)\ttotal: 1m 9s\tremaining: 24.9s\n",
      "1500:\tlearn: 0.7577513\ttest: 0.7230774\tbest: 0.7230774 (1497)\ttotal: 1m 14s\tremaining: 19.8s\n",
      "1600:\tlearn: 0.7625800\ttest: 0.7249306\tbest: 0.7249306 (1574)\ttotal: 1m 19s\tremaining: 14.8s\n",
      "1700:\tlearn: 0.7646601\ttest: 0.7268274\tbest: 0.7268274 (1700)\ttotal: 1m 24s\tremaining: 9.88s\n",
      "1800:\tlearn: 0.7673600\ttest: 0.7287435\tbest: 0.7299326 (1731)\ttotal: 1m 29s\tremaining: 4.92s\n",
      "1899:\tlearn: 0.7701172\ttest: 0.7328968\tbest: 0.7332222 (1892)\ttotal: 1m 34s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.7332221824\n",
      "bestIteration = 1892\n",
      "\n",
      "Shrink model to first 1893 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alrxp\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [500, 2000] and step=200, but the range is not divisible by `step`. It will be replaced by [500, 1900].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.4919946\ttest: 0.4759614\tbest: 0.4759614 (0)\ttotal: 125ms\tremaining: 1m 2s\n",
      "100:\tlearn: 0.7064500\ttest: 0.6923211\tbest: 0.6933821 (98)\ttotal: 12s\tremaining: 47.5s\n",
      "200:\tlearn: 0.7529236\ttest: 0.7143593\tbest: 0.7143593 (200)\ttotal: 23.4s\tremaining: 34.8s\n",
      "300:\tlearn: 0.7755691\ttest: 0.7344126\tbest: 0.7347891 (277)\ttotal: 35s\tremaining: 23.2s\n",
      "400:\tlearn: 0.7887572\ttest: 0.7435863\tbest: 0.7435863 (399)\ttotal: 46.5s\tremaining: 11.5s\n",
      "499:\tlearn: 0.7995589\ttest: 0.7421718\tbest: 0.7488047 (486)\ttotal: 57.8s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.7488047402\n",
      "bestIteration = 486\n",
      "\n",
      "Shrink model to first 487 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alrxp\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [500, 2000] and step=200, but the range is not divisible by `step`. It will be replaced by [500, 1900].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.4847216\ttest: 0.4682424\tbest: 0.4682424 (0)\ttotal: 72.9ms\tremaining: 51s\n",
      "100:\tlearn: 0.6629730\ttest: 0.6566255\tbest: 0.6566255 (100)\ttotal: 9.48s\tremaining: 56.2s\n",
      "200:\tlearn: 0.7037670\ttest: 0.6875957\tbest: 0.6882534 (198)\ttotal: 18.7s\tremaining: 46.5s\n",
      "300:\tlearn: 0.7281873\ttest: 0.7054898\tbest: 0.7058931 (290)\ttotal: 27.9s\tremaining: 37s\n",
      "400:\tlearn: 0.7478171\ttest: 0.7141805\tbest: 0.7148735 (370)\ttotal: 37.2s\tremaining: 27.8s\n",
      "500:\tlearn: 0.7603097\ttest: 0.7210600\tbest: 0.7213853 (497)\ttotal: 46.4s\tremaining: 18.4s\n",
      "600:\tlearn: 0.7704588\ttest: 0.7295289\tbest: 0.7295289 (581)\ttotal: 55.9s\tremaining: 9.21s\n",
      "699:\tlearn: 0.7793817\ttest: 0.7325067\tbest: 0.7328035 (664)\ttotal: 1m 5s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.7328034644\n",
      "bestIteration = 664\n",
      "\n",
      "Shrink model to first 665 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alrxp\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [500, 2000] and step=200, but the range is not divisible by `step`. It will be replaced by [500, 1900].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.4995109\ttest: 0.4926757\tbest: 0.4926757 (0)\ttotal: 680ms\tremaining: 16m 59s\n",
      "100:\tlearn: 0.7375279\ttest: 0.7077130\tbest: 0.7077130 (100)\ttotal: 37.5s\tremaining: 8m 40s\n",
      "200:\tlearn: 0.7802135\ttest: 0.7348476\tbest: 0.7350036 (195)\ttotal: 1m 13s\tremaining: 7m 52s\n",
      "300:\tlearn: 0.8015806\ttest: 0.7435920\tbest: 0.7445966 (299)\ttotal: 1m 48s\tremaining: 7m 12s\n",
      "400:\tlearn: 0.8141132\ttest: 0.7474748\tbest: 0.7490935 (382)\ttotal: 2m 24s\tremaining: 6m 36s\n",
      "500:\tlearn: 0.8243012\ttest: 0.7514291\tbest: 0.7521858 (431)\ttotal: 2m 59s\tremaining: 5m 58s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.7521858001\n",
      "bestIteration = 431\n",
      "\n",
      "Shrink model to first 432 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alrxp\\anaconda3\\Lib\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [500, 2000] and step=200, but the range is not divisible by `step`. It will be replaced by [500, 1900].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5012050\ttest: 0.4866801\tbest: 0.4866801 (0)\ttotal: 338ms\tremaining: 7m 18s\n",
      "100:\tlearn: 0.7091296\ttest: 0.6972405\tbest: 0.6995819 (97)\ttotal: 32.4s\tremaining: 6m 25s\n",
      "200:\tlearn: 0.7632866\ttest: 0.7284256\tbest: 0.7284256 (200)\ttotal: 1m 4s\tremaining: 5m 51s\n",
      "300:\tlearn: 0.7883671\ttest: 0.7392175\tbest: 0.7399531 (292)\ttotal: 1m 36s\tremaining: 5m 18s\n",
      "400:\tlearn: 0.8086442\ttest: 0.7463711\tbest: 0.7463711 (400)\ttotal: 2m 7s\tremaining: 4m 45s\n",
      "500:\tlearn: 0.8213135\ttest: 0.7502744\tbest: 0.7525873 (479)\ttotal: 2m 39s\tremaining: 4m 13s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.7525873244\n",
      "bestIteration = 479\n",
      "\n",
      "Shrink model to first 480 iterations.\n"
     ]
    }
   ],
   "source": [
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "study_catboost.optimize(objective_catboost, n_trials=10,show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7983e203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'iterations': 500,\n",
       " 'depth': 5,\n",
       " 'learning_rate': 0.12,\n",
       " 'l2_leaf_reg': 0.16960494498640707,\n",
       " 'colsample_bylevel': 0.23613115193045567}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_catboost.best_params #Параметры лучшей модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e07c8ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cb_model = catboost.CatBoostClassifier(**study_catboost.best_params) #лучшая модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "293dba2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.6741021\ttest: 1.6680147\tbest: 1.6680147 (0)\ttotal: 120ms\tremaining: 59.7s\n",
      "100:\tlearn: 0.9673294\ttest: 0.9834026\tbest: 0.9832746 (99)\ttotal: 17.7s\tremaining: 1m 10s\n",
      "200:\tlearn: 0.8446145\ttest: 0.9222759\tbest: 0.9222355 (199)\ttotal: 35.6s\tremaining: 52.9s\n",
      "300:\tlearn: 0.7704406\ttest: 0.8988053\tbest: 0.8985376 (299)\ttotal: 54.3s\tremaining: 35.9s\n",
      "400:\tlearn: 0.7148313\ttest: 0.8798525\tbest: 0.8798525 (400)\ttotal: 1m 13s\tremaining: 18.1s\n",
      "499:\tlearn: 0.6717635\ttest: 0.8729500\tbest: 0.8717626 (475)\ttotal: 1m 32s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.8717625816\n",
      "bestIteration = 475\n",
      "\n",
      "Shrink model to first 476 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x2b1c1c3b0d0>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_cb_model.fit(train_pool,\n",
    "                  eval_set = test_pool,\n",
    "                  verbose=100,\n",
    "                  early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "89da17a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_preds = best_cb_model.predict(valid_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ab0f4760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6189451022604952"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(valid['SentimentScore'].values, best_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9bdc02",
   "metadata": {},
   "source": [
    "# Обучение ruBERT-tiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "bf27a4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {\n",
    "    'very_negative': 0,\n",
    "    'negative': 1,\n",
    "    'neutral': 2,\n",
    "    'positive': 3,\n",
    "    'very_positive': 4\n",
    "}\n",
    "\n",
    "id2label = {\n",
    "    0: 'very_negative',\n",
    "    1: 'negative',\n",
    "    2: 'neutral',\n",
    "    3: 'positive',\n",
    "    4: 'very_positive'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f3209a-9f95-42c6-9f48-4f524f49e153",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_texts.SentimentScore -= 1 #Вычитаем единицу, т.к. первый класс для rubert-tiny - 0, а не 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "9e233035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 5, 3, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_texts.SentimentScore.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "fba86670",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cointegrated/rubert-tiny were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"cointegrated/rubert-tiny\", num_labels=len(id2label.keys()), label2id=label2id, id2label=id2label\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "b15eb05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list_of_dicts = [] #приводим данные к виду для обучения\n",
    "for idx, row in sentiment_texts.iterrows():\n",
    "    text = row['MessageText']\n",
    "    label = row['SentimentScore']\n",
    "    data_list_of_dicts.append({'text': text, 'label': label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "f777b8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny\")\n",
    "def tokenize_data(text):\n",
    "    return tokenizer(text['text'], padding=True, truncation=True, max_length=256, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "9718e2a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7300 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1826 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shuffle(data_list_of_dicts)\n",
    "train_bert = data_list_of_dicts[:7300]\n",
    "test_bert = data_list_of_dicts[7300:]\n",
    "train_bert = Dataset.from_pandas(pd.DataFrame(data=train_bert))\n",
    "test_bert = Dataset.from_pandas(pd.DataFrame(data=test_bert))\n",
    "tokenized_train = train_bert.map(tokenize_data, batched=True)\n",
    "tokenized_test = test_bert.map(tokenize_data, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "d3a7d3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred): #функция для подсчета метрик\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    f1_score = f1.compute(predictions=predictions, references=labels, average='macro')\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    \n",
    "    return {'f1': f1_score, 'accuracy': accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "e7455547",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"akra_model\",\n",
    "    learning_rate=2e-3,\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=7,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "e91a76ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='805' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  9/805 00:49 < 1:34:30, 0.14 it/s, Epoch 0.07/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[577], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\trainer.py:1645\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1640\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m   1642\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[0;32m   1643\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[0;32m   1644\u001b[0m )\n\u001b[1;32m-> 1645\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   1646\u001b[0m     args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   1647\u001b[0m     resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[0;32m   1648\u001b[0m     trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[0;32m   1649\u001b[0m     ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[0;32m   1650\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\trainer.py:1929\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1926\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m   1928\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m-> 1929\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[0;32m   1931\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1932\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   1933\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m   1934\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   1935\u001b[0m ):\n\u001b[0;32m   1936\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   1937\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\trainer.py:2750\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   2747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m   2749\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[1;32m-> 2750\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(model, inputs)\n\u001b[0;32m   2752\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   2753\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\trainer.py:2775\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[1;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[0;32m   2773\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2774\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2775\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m   2776\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[0;32m   2777\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[0;32m   2778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1562\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1554\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1555\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1560\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1562\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbert(\n\u001b[0;32m   1563\u001b[0m     input_ids,\n\u001b[0;32m   1564\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   1565\u001b[0m     token_type_ids\u001b[38;5;241m=\u001b[39mtoken_type_ids,\n\u001b[0;32m   1566\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   1567\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m   1568\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[0;32m   1569\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1570\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m   1571\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m   1572\u001b[0m )\n\u001b[0;32m   1574\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   1576\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1020\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1011\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m   1013\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[0;32m   1014\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   1015\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1018\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[0;32m   1019\u001b[0m )\n\u001b[1;32m-> 1020\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[0;32m   1021\u001b[0m     embedding_output,\n\u001b[0;32m   1022\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mextended_attention_mask,\n\u001b[0;32m   1023\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m   1024\u001b[0m     encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states,\n\u001b[0;32m   1025\u001b[0m     encoder_attention_mask\u001b[38;5;241m=\u001b[39mencoder_extended_attention_mask,\n\u001b[0;32m   1026\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m   1027\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m   1028\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1029\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m   1030\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m   1031\u001b[0m )\n\u001b[0;32m   1032\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1033\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:610\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    601\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[0;32m    602\u001b[0m         create_custom_forward(layer_module),\n\u001b[0;32m    603\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    607\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    608\u001b[0m     )\n\u001b[0;32m    609\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 610\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m layer_module(\n\u001b[0;32m    611\u001b[0m         hidden_states,\n\u001b[0;32m    612\u001b[0m         attention_mask,\n\u001b[0;32m    613\u001b[0m         layer_head_mask,\n\u001b[0;32m    614\u001b[0m         encoder_hidden_states,\n\u001b[0;32m    615\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    616\u001b[0m         past_key_value,\n\u001b[0;32m    617\u001b[0m         output_attentions,\n\u001b[0;32m    618\u001b[0m     )\n\u001b[0;32m    620\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:537\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    534\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    535\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[1;32m--> 537\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m apply_chunking_to_forward(\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeed_forward_chunk, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_size_feed_forward, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_len_dim, attention_output\n\u001b[0;32m    539\u001b[0m )\n\u001b[0;32m    540\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[0;32m    542\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\pytorch_utils.py:237\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[1;32m--> 237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m forward_fn(\u001b[38;5;241m*\u001b[39minput_tensors)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:550\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[0;32m    549\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate(attention_output)\n\u001b[1;32m--> 550\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[0;32m    551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:463\u001b[0m, in \u001b[0;36mBertOutput.forward\u001b[1;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor, input_tensor: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m    462\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(hidden_states)\n\u001b[1;32m--> 463\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[0;32m    464\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(hidden_states \u001b[38;5;241m+\u001b[39m input_tensor)\n\u001b[0;32m    465\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:58\u001b[0m, in \u001b[0;36mDropout.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m---> 58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minplace)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\functional.py:1266\u001b[0m, in \u001b[0;36mdropout\u001b[1;34m(input, p, training, inplace)\u001b[0m\n\u001b[0;32m   1264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[0;32m   1265\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1266\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28minput\u001b[39m, p, training)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "a3f0986b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.829366  , -0.11736619,  0.95662   ,  0.9494317 ,  0.27798185]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(single_test['input_ids'], single_test['token_type_ids'], single_test['attention_mask']).logits.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c49835",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
